{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a classification technique based on Bayes’ Theorem with an assumption of independence among predictors. In simple terms, a Naive Bayes classifier assumes that the presence of a particular feature in a class is unrelated to the presence of any other feature.\n",
    "\n",
    "For example, a fruit may be considered to be an apple if it is red, round, and about 3 inches in diameter. Even if these features depend on each other or upon the existence of the other features, all of these properties independently contribute to the probability that this fruit is an apple and that is why it is known as ‘Naive’.\n",
    "\n",
    "Naive Bayes model is easy to build and particularly useful for very large data sets. Along with simplicity, Naive Bayes is known to outperform even highly sophisticated classification methods.\n",
    "\n",
    "Naive Bayes is a classification algorithm for binary (two-class) and multi-class classification problems. The technique is easiest to understand when described using binary or categorical input values.\n",
    "\n",
    "It is called naive Bayes because the calculation of the probabilities for each hypothesis are simplified to make their calculation tractable. Rather than attempting to calculate the values of each attribute value P(d1, d2, d3|h), they are assumed to be conditionally independent given the target value and calculated as P(d1|h) * P(d2|H) and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes' Theorem\n",
    "Bayes’ Theorem is stated as:\n",
    "\n",
    "P(h|d) = (P(d|h) * P(h)) / P(d)\n",
    "\n",
    "Where\n",
    "\n",
    "###### P(h|d) is the probability of hypothesis h given the data d. This is called the posterior probability.\n",
    "###### P(d|h) is the probability of data d given that the hypothesis h was true.\n",
    "###### P(h) is the probability of hypothesis h being true (regardless of the data). This is called the prior probability of h.\n",
    "###### P(d) is the probability of the data (regardless of the hypothesis)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful Libraries"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "To load dataset:    import pandas as pd\n",
    "Preprocessing:      from sklearn import preprocessing\n",
    "NB Classifier:      from sklearn.naive_bayes import GaussianNB\n",
    "Train & Test Split: from sklearn.model_selection import train_test_split\n",
    "K-Fold:             from sklearn.model_selection import cross_val_score\n",
    "\n",
    "For Prediction and Evaluation\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Dataset. Use \"bank-data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id  age     sex      region   income married  children  car  \\\n",
      "0    ID12101   48  FEMALE  INNER_CITY  17546.0      NO         1   NO   \n",
      "1    ID12102   40    MALE        TOWN  30085.1     YES         3  YES   \n",
      "2    ID12103   51  FEMALE  INNER_CITY  16575.4     YES         0  YES   \n",
      "3    ID12104   23  FEMALE        TOWN  20375.4     YES         3   NO   \n",
      "4    ID12105   57  FEMALE       RURAL  50576.3     YES         0   NO   \n",
      "..       ...  ...     ...         ...      ...     ...       ...  ...   \n",
      "474  ID12575   31  FEMALE        TOWN  22678.1      NO         1  YES   \n",
      "475  ID12576   33  FEMALE        TOWN  12178.5     YES         2   NO   \n",
      "476  ID12577   43    MALE       RURAL  26106.7      NO         1   NO   \n",
      "477  ID12578   40    MALE  INNER_CITY  27417.6     YES         0   NO   \n",
      "478  ID12579   47    MALE        TOWN  23337.2     YES         2   NO   \n",
      "\n",
      "    save_act current_act mortgage  pep  \n",
      "0         NO          NO       NO  YES  \n",
      "1         NO         YES      YES   NO  \n",
      "2        YES         YES       NO   NO  \n",
      "3         NO         YES       NO   NO  \n",
      "4        YES          NO       NO   NO  \n",
      "..       ...         ...      ...  ...  \n",
      "474      YES         YES      YES  YES  \n",
      "475      YES         YES      YES   NO  \n",
      "476       NO         YES       NO  YES  \n",
      "477      YES         YES      YES   NO  \n",
      "478      YES         YES      YES   NO  \n",
      "\n",
      "[479 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "# import dataset\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"bank-data.csv\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library for preprocessing\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id       age       sex   region    income   married  children  \\\n",
      "0    ID12101  0.365673  1.018969 -0.97830 -0.783389 -1.385905 -0.007880   \n",
      "1    ID12102 -0.183625 -0.981384  0.73194  0.190099  0.721550  1.879330   \n",
      "2    ID12103  0.571660  1.018969 -0.97830 -0.858742  0.721550 -0.951485   \n",
      "3    ID12104 -1.350884  1.018969  0.73194 -0.563725  0.721550  1.879330   \n",
      "4    ID12105  0.983634  1.018969  1.58706  1.780957  0.721550 -0.951485   \n",
      "..       ...       ...       ...      ...       ...       ...       ...   \n",
      "474  ID12575 -0.801586  1.018969  0.73194 -0.384952 -1.385905 -0.007880   \n",
      "475  ID12576 -0.664261  1.018969  0.73194 -1.200101  0.721550  0.935725   \n",
      "476  ID12577  0.022362 -0.981384  1.58706 -0.118769 -1.385905 -0.007880   \n",
      "477  ID12578 -0.183625 -0.981384 -0.97830 -0.016995  0.721550 -0.951485   \n",
      "478  ID12579  0.297011 -0.981384  0.73194 -0.333782  0.721550  0.935725   \n",
      "\n",
      "          car  save_act  current_act  mortgage  pep  \n",
      "0   -0.965117 -1.452718    -1.799705 -0.718208    1  \n",
      "1    1.036143 -1.452718     0.555647  1.392354    0  \n",
      "2    1.036143  0.688365     0.555647 -0.718208    0  \n",
      "3   -0.965117 -1.452718     0.555647 -0.718208    0  \n",
      "4   -0.965117  0.688365    -1.799705 -0.718208    0  \n",
      "..        ...       ...          ...       ...  ...  \n",
      "474  1.036143  0.688365     0.555647  1.392354    1  \n",
      "475 -0.965117  0.688365     0.555647  1.392354    0  \n",
      "476 -0.965117 -1.452718     0.555647 -0.718208    1  \n",
      "477 -0.965117  0.688365     0.555647  1.392354    0  \n",
      "478 -0.965117  0.688365     0.555647  1.392354    0  \n",
      "\n",
      "[479 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "# Tranform data using \"fit_transform(attribute)\" function\n",
    "# converting string attributes to numeric attributes\n",
    "df = df.replace({\"sex\": {\"MALE\": 0, \"FEMALE\": 1},\n",
    "                 \"region\": {\"INNER_CITY\": 0, \"SUBURBAN\": 1, \"TOWN\": 2, \"RURAL\": 3},\n",
    "                 \"married\": {\"NO\": 0, \"YES\": 1}, \n",
    "                 \"car\": {\"NO\": 0, \"YES\": 1}, \n",
    "                 \"save_act\": {\"NO\": 0, \"YES\": 1}, \n",
    "                 \"current_act\": {\"NO\": 0, \"YES\": 1}, \n",
    "                 \"mortgage\": {\"NO\": 0, \"YES\": 1}, \n",
    "                 \"pep\": {\"NO\": 0, \"YES\": 1}})\n",
    "\n",
    "# normalizing relevant attributes\n",
    "df[[\"age\", \"sex\", \"region\", \"income\", \"married\", \"children\",\n",
    "    \"car\", \"save_act\", \"current_act\", \"mortgage\"]] = \\\n",
    "preprocessing.StandardScaler().fit_transform(df[[\"age\", \"sex\", \"region\", \"income\", \"married\",\n",
    "                                                 \"children\", \"car\", \"save_act\", \"current_act\", \"mortgage\"]])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select independent variables and target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.36567334  1.01896902 -0.97830006 ... -1.45271801 -1.79970499\n",
      "  -0.71820804]\n",
      " [-0.18362507 -0.9813841   0.73193983 ... -1.45271801  0.55564662\n",
      "   1.39235423]\n",
      " [ 0.57166024  1.01896902 -0.97830006 ...  0.68836484  0.55564662\n",
      "  -0.71820804]\n",
      " ...\n",
      " [ 0.02236183 -0.9813841   1.58705977 ... -1.45271801  0.55564662\n",
      "  -0.71820804]\n",
      " [-0.18362507 -0.9813841  -0.97830006 ...  0.68836484  0.55564662\n",
      "   1.39235423]\n",
      " [ 0.29701104 -0.9813841   0.73193983 ...  0.68836484  0.55564662\n",
      "   1.39235423]]\n",
      "[1 0 0 0 0 1 1 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 1 0 0 1 0 1 0 0\n",
      " 1 0 0 1 0 1 0 0 1 1 1 1 0 0 0 1 1 0 1 1 1 0 1 1 1 0 0 0 0 0 0 0 1 0 1 1 0\n",
      " 1 1 0 1 0 1 1 0 0 1 1 1 0 0 0 1 1 0 1 0 0 0 0 1 0 0 1 0 1 0 1 0 0 0 1 0 1\n",
      " 0 0 1 1 0 0 0 1 1 0 1 1 1 1 1 0 0 0 1 0 0 0 0 1 1 0 1 0 1 0 0 0 0 1 1 0 0\n",
      " 0 0 1 1 1 1 0 1 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 1 0 1 1 1 1 1 0 0 0\n",
      " 1 1 1 0 0 1 0 1 1 1 1 1 1 0 1 1 0 0 0 1 1 1 0 0 1 1 1 1 1 0 0 0 0 1 0 0 1\n",
      " 1 0 1 1 1 1 1 1 1 0 1 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0\n",
      " 0 0 1 0 0 1 1 1 1 0 0 1 1 0 1 0 1 1 1 0 1 1 0 1 0 0 0 1 0 0 1 1 1 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 1 1 0 0 0 0 1 0 0 1 1 0 1 0 1 1 1 1 0 1 0 0\n",
      " 0 1 1 0 0 1 1 0 1 0 0 0 1 0 0 0 1 1 0 0 1 1 1 0 1 0 1 1 0 0 0 1 1 1 0 0 0\n",
      " 0 1 1 0 1 0 1 0 1 0 1 0 0 1 0 0 0 1 1 0 0 1 0 0 1 0 0 1 1 0 1 0 0 1 1 1 1\n",
      " 1 1 0 1 0 1 1 0 0 0 1 1 0 0 1 0 0 1 0 0 1 1 0 0 1 0 1 0 0 1 1 0 0 1 0 0 1\n",
      " 1 0 0 1 1 1 0 0 1 0 0 0 0 0 0 1 1 0 1 0 1 0 0 1 1 0 0 0 0 1 1 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Select the independent variables and the target attribute\n",
    "X = df[[\"age\", \"sex\", \"region\", \"income\", \"married\", \"children\",\n",
    "    \"car\", \"save_act\", \"current_act\", \"mortgage\"]].values\n",
    "Y = df[\"pep\"].values\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Naive Bayes Classifier library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Classifier library\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the Classifier\n",
    "naive = GaussianNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict the target column and find the perfromance of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the dataset into training and testing partition\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=1)\n",
    "\n",
    "# fit the data\n",
    "naive.fit(X_train, Y_train)\n",
    "Y_pred = naive.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n"
     ]
    }
   ],
   "source": [
    "# Print Number of mislabeled points\n",
    "print((Y_pred != Y_test).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.84      0.65        67\n",
      "           1       0.72      0.38      0.50        77\n",
      "\n",
      "    accuracy                           0.59       144\n",
      "   macro avg       0.63      0.61      0.58       144\n",
      "weighted avg       0.64      0.59      0.57       144\n",
      "\n",
      "Confusion Matrix\n",
      "[[56 11]\n",
      " [48 29]]\n",
      "\n",
      " Accuracy\n",
      "0.5902777777777778\n"
     ]
    }
   ],
   "source": [
    "# Calculate and print confusion matrix and other performance measures (Refer previous labsheet)\n",
    "print(classification_report(Y_test, Y_pred))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(Y_test, Y_pred))\n",
    "print(\"\\n Accuracy\")\n",
    "print(accuracy_score(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1: Consider \"current_act\" as an irrelevant attribute. Remove it and find the accuracy of Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id       age       sex   region    income   married  children  \\\n",
      "0  ID12101  0.365673  1.018969 -0.97830 -0.783389 -1.385905 -0.007880   \n",
      "1  ID12102 -0.183625 -0.981384  0.73194  0.190099  0.721550  1.879330   \n",
      "2  ID12103  0.571660  1.018969 -0.97830 -0.858742  0.721550 -0.951485   \n",
      "3  ID12104 -1.350884  1.018969  0.73194 -0.563725  0.721550  1.879330   \n",
      "4  ID12105  0.983634  1.018969  1.58706  1.780957  0.721550 -0.951485   \n",
      "\n",
      "        car  save_act  mortgage  pep  \n",
      "0 -0.965117 -1.452718 -0.718208    1  \n",
      "1  1.036143 -1.452718  1.392354    0  \n",
      "2  1.036143  0.688365 -0.718208    0  \n",
      "3 -0.965117 -1.452718 -0.718208    0  \n",
      "4 -0.965117  0.688365 -0.718208    0  \n"
     ]
    }
   ],
   "source": [
    "# display dataframe first 5 columns\n",
    "df = df.drop([\"current_act\"], axis = 1)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.36567334  1.01896902 -0.97830006 ... -0.96511741 -1.45271801\n",
      "  -0.71820804]\n",
      " [-0.18362507 -0.9813841   0.73193983 ...  1.03614337 -1.45271801\n",
      "   1.39235423]\n",
      " [ 0.57166024  1.01896902 -0.97830006 ...  1.03614337  0.68836484\n",
      "  -0.71820804]\n",
      " ...\n",
      " [ 0.02236183 -0.9813841   1.58705977 ... -0.96511741 -1.45271801\n",
      "  -0.71820804]\n",
      " [-0.18362507 -0.9813841  -0.97830006 ... -0.96511741  0.68836484\n",
      "   1.39235423]\n",
      " [ 0.29701104 -0.9813841   0.73193983 ... -0.96511741  0.68836484\n",
      "   1.39235423]]\n"
     ]
    }
   ],
   "source": [
    "# Selecting the independent variables\n",
    "X = df[[\"age\", \"sex\", \"region\", \"income\", \"married\", \"children\",\n",
    "    \"car\", \"save_act\", \"mortgage\"]].values\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 0 0 1 1 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 1 0 0 1 0 1 0 0\n",
      " 1 0 0 1 0 1 0 0 1 1 1 1 0 0 0 1 1 0 1 1 1 0 1 1 1 0 0 0 0 0 0 0 1 0 1 1 0\n",
      " 1 1 0 1 0 1 1 0 0 1 1 1 0 0 0 1 1 0 1 0 0 0 0 1 0 0 1 0 1 0 1 0 0 0 1 0 1\n",
      " 0 0 1 1 0 0 0 1 1 0 1 1 1 1 1 0 0 0 1 0 0 0 0 1 1 0 1 0 1 0 0 0 0 1 1 0 0\n",
      " 0 0 1 1 1 1 0 1 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 1 0 1 1 1 1 1 0 0 0\n",
      " 1 1 1 0 0 1 0 1 1 1 1 1 1 0 1 1 0 0 0 1 1 1 0 0 1 1 1 1 1 0 0 0 0 1 0 0 1\n",
      " 1 0 1 1 1 1 1 1 1 0 1 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0\n",
      " 0 0 1 0 0 1 1 1 1 0 0 1 1 0 1 0 1 1 1 0 1 1 0 1 0 0 0 1 0 0 1 1 1 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 1 1 0 0 0 0 1 0 0 1 1 0 1 0 1 1 1 1 0 1 0 0\n",
      " 0 1 1 0 0 1 1 0 1 0 0 0 1 0 0 0 1 1 0 0 1 1 1 0 1 0 1 1 0 0 0 1 1 1 0 0 0\n",
      " 0 1 1 0 1 0 1 0 1 0 1 0 0 1 0 0 0 1 1 0 0 1 0 0 1 0 0 1 1 0 1 0 0 1 1 1 1\n",
      " 1 1 0 1 0 1 1 0 0 0 1 1 0 0 1 0 0 1 0 0 1 1 0 0 1 0 1 0 0 1 1 0 0 1 0 0 1\n",
      " 1 0 0 1 1 1 0 0 1 0 0 0 0 0 0 1 1 0 1 0 1 0 0 1 1 0 0 0 0 1 1 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "# selecting only the target lableled column\n",
    "Y = df[\"pep\"].values\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58\n"
     ]
    }
   ],
   "source": [
    "# Apply the classifier and Print Number of mislabeled points\n",
    "naive = GaussianNB()\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=1)\n",
    "naive.fit(X_train, Y_train)\n",
    "Y_pred = naive.predict(X_test)\n",
    "print((Y_pred != Y_test).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.87      0.67        67\n",
      "           1       0.76      0.36      0.49        77\n",
      "\n",
      "    accuracy                           0.60       144\n",
      "   macro avg       0.65      0.61      0.58       144\n",
      "weighted avg       0.66      0.60      0.57       144\n",
      "\n",
      "Confusion Matrix\n",
      "[[58  9]\n",
      " [49 28]]\n",
      "\n",
      " Accuracy\n",
      "0.5972222222222222\n"
     ]
    }
   ],
   "source": [
    "# Calculate and print confusion matrix and other performance measures\n",
    "print(classification_report(Y_test, Y_pred))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(Y_test, Y_pred))\n",
    "print(\"\\n Accuracy\")\n",
    "print(accuracy_score(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2: Write your observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the accuracy slightly went up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load \"car.csv\" dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q3: Apply Naive Bayes classifier on this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0      1  2  3      4     5      6\n",
      "746    high    med  6  4    big  high    acc\n",
      "179   vhigh   high  4  4    big  high  unacc\n",
      "1521    low    med  2  4  small   low  unacc\n",
      "694    high    med  3  6  small   med  unacc\n",
      "1374    low  vhigh  4  6    big   low  unacc\n",
      "...     ...    ... .. ..    ...   ...    ...\n",
      "848    high    low  6  4  small  high    acc\n",
      "1706    low    low  6  2    med  high  unacc\n",
      "484    high  vhigh  3  6    big   med  unacc\n",
      "449    high  vhigh  2  4    big  high  unacc\n",
      "1266    med    low  4  6    big   low  unacc\n",
      "\n",
      "[1728 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv(\"car.csv\", header = None)\n",
    "# shuffle the DataFrame rows\n",
    "df = df.sample(frac = 1)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             0         1         2         3         4         5  6\n",
      "746   0.447214 -0.447214  1.521278  0.000000  1.224745  1.224745  1\n",
      "179   1.341641  0.447214  0.169031  0.000000  1.224745  1.224745  0\n",
      "1521 -1.341641 -0.447214 -1.183216  0.000000 -1.224745 -1.224745  0\n",
      "694   0.447214 -0.447214 -0.507093  1.224745 -1.224745  0.000000  0\n",
      "1374 -1.341641  1.341641  0.169031  1.224745  1.224745 -1.224745  0\n",
      "...        ...       ...       ...       ...       ...       ... ..\n",
      "848   0.447214 -1.341641  1.521278  0.000000 -1.224745  1.224745  1\n",
      "1706 -1.341641 -1.341641  1.521278 -1.224745  0.000000  1.224745  0\n",
      "484   0.447214  1.341641 -0.507093  1.224745  1.224745  0.000000  0\n",
      "449   0.447214  1.341641 -1.183216  0.000000  1.224745  1.224745  0\n",
      "1266 -0.447214 -1.341641  0.169031  1.224745  1.224745 -1.224745  0\n",
      "\n",
      "[1728 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Preprocess and Tranform data using \"fit_transform(attribute)\" function\n",
    "# converting string attributes to numeric attributes\n",
    "df = df.replace({0: {\"low\": 0, \"med\": 1, \"high\": 2, \"vhigh\": 3},\n",
    "                1: {\"low\": 0, \"med\": 1, \"high\": 2, \"vhigh\": 3},\n",
    "                4: {\"small\": 0, \"med\": 1, \"big\": 2},\n",
    "                5: {\"low\": 0, \"med\": 1, \"high\": 2},\n",
    "                6: {\"unacc\": 0, \"acc\": 1, \"good\": 2, \"vgood\": 3}})\n",
    "\n",
    "# normalizing relevant attributes\n",
    "df[df.columns[0:6]] = preprocessing.StandardScaler().fit_transform(df[df.columns[0:6]])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             0         1         2         3         4         5\n",
      "746   0.447214 -0.447214  1.521278  0.000000  1.224745  1.224745\n",
      "179   1.341641  0.447214  0.169031  0.000000  1.224745  1.224745\n",
      "1521 -1.341641 -0.447214 -1.183216  0.000000 -1.224745 -1.224745\n",
      "694   0.447214 -0.447214 -0.507093  1.224745 -1.224745  0.000000\n",
      "1374 -1.341641  1.341641  0.169031  1.224745  1.224745 -1.224745\n",
      "...        ...       ...       ...       ...       ...       ...\n",
      "848   0.447214 -1.341641  1.521278  0.000000 -1.224745  1.224745\n",
      "1706 -1.341641 -1.341641  1.521278 -1.224745  0.000000  1.224745\n",
      "484   0.447214  1.341641 -0.507093  1.224745  1.224745  0.000000\n",
      "449   0.447214  1.341641 -1.183216  0.000000  1.224745  1.224745\n",
      "1266 -0.447214 -1.341641  0.169031  1.224745  1.224745 -1.224745\n",
      "\n",
      "[1728 rows x 6 columns]\n",
      "746     1\n",
      "179     0\n",
      "1521    0\n",
      "694     0\n",
      "1374    0\n",
      "       ..\n",
      "848     1\n",
      "1706    0\n",
      "484     0\n",
      "449     0\n",
      "1266    0\n",
      "Name: 6, Length: 1728, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Select the independent variables and the target attribute\n",
    "X = df[df.columns[0:6]]\n",
    "Y = df[df.columns[6]]\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the classifier\n",
    "naive = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the dataset into training and testing partition\n",
    "# predictions for testing partition\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=1)\n",
    "naive.fit(X_train, Y_train)\n",
    "Y_pred = naive.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185\n"
     ]
    }
   ],
   "source": [
    "# Print Number of mislabeled points\n",
    "print((Y_pred != Y_test).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.85      0.83       343\n",
      "           1       0.47      0.11      0.18       133\n",
      "           2       0.69      0.39      0.50        23\n",
      "           3       0.17      1.00      0.29        20\n",
      "\n",
      "    accuracy                           0.64       519\n",
      "   macro avg       0.54      0.59      0.45       519\n",
      "weighted avg       0.69      0.64      0.63       519\n",
      "\n",
      "Confusion Matrix\n",
      "[[290  12   0  41]\n",
      " [ 64  15   4  50]\n",
      " [  3   5   9   6]\n",
      " [  0   0   0  20]]\n",
      "\n",
      " Accuracy\n",
      "0.6435452793834296\n"
     ]
    }
   ],
   "source": [
    "# Calculate and print confusion matrix and other performance measures\n",
    "print(classification_report(Y_test, Y_pred))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(Y_test, Y_pred))\n",
    "print(\"\\n Accuracy\")\n",
    "print(accuracy_score(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q4: Find the correlation between the attributes of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6  0   -2.827504e-01\n",
       "0  6   -2.827504e-01\n",
       "1  6   -2.324215e-01\n",
       "6  1   -2.324215e-01\n",
       "2  1   -3.350586e-17\n",
       "1  2   -3.350586e-17\n",
       "4  1   -7.966878e-18\n",
       "1  4   -7.966878e-18\n",
       "   5   -1.541976e-18\n",
       "5  1   -1.541976e-18\n",
       "0  1   -1.156482e-18\n",
       "1  0   -1.156482e-18\n",
       "3  4   -7.709882e-19\n",
       "5  3   -7.709882e-19\n",
       "1  3   -7.709882e-19\n",
       "3  5   -7.709882e-19\n",
       "   1   -7.709882e-19\n",
       "4  3   -7.709882e-19\n",
       "5  4   -2.569961e-19\n",
       "4  5   -2.569961e-19\n",
       "   2    7.067392e-19\n",
       "2  4    7.067392e-19\n",
       "   3    7.709882e-19\n",
       "3  2    7.709882e-19\n",
       "0  4    1.798972e-18\n",
       "4  0    1.798972e-18\n",
       "2  5    5.718163e-18\n",
       "5  2    5.718163e-18\n",
       "3  0    5.910910e-18\n",
       "0  3    5.910910e-18\n",
       "5  0    7.709882e-18\n",
       "0  5    7.709882e-18\n",
       "2  0    8.063252e-18\n",
       "0  2    8.063252e-18\n",
       "2  6    5.984170e-02\n",
       "6  2    5.984170e-02\n",
       "4  6    1.579317e-01\n",
       "6  4    1.579317e-01\n",
       "   3    3.417068e-01\n",
       "3  6    3.417068e-01\n",
       "6  5    4.393373e-01\n",
       "5  6    4.393373e-01\n",
       "0  0    1.000000e+00\n",
       "3  3    1.000000e+00\n",
       "4  4    1.000000e+00\n",
       "2  2    1.000000e+00\n",
       "1  1    1.000000e+00\n",
       "5  5    1.000000e+00\n",
       "6  6    1.000000e+00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the pairwise correlation of attributes and arrange in ascending order\n",
    "df.corr().unstack().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q5: Remove one of the highly correlated attributes and apply Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             0         2         3         4         5  6\n",
      "746   0.447214  1.521278  0.000000  1.224745  1.224745  1\n",
      "179   1.341641  0.169031  0.000000  1.224745  1.224745  0\n",
      "1521 -1.341641 -1.183216  0.000000 -1.224745 -1.224745  0\n",
      "694   0.447214 -0.507093  1.224745 -1.224745  0.000000  0\n",
      "1374 -1.341641  0.169031  1.224745  1.224745 -1.224745  0\n"
     ]
    }
   ],
   "source": [
    "# Drop highly correlated attribute\n",
    "df = df.drop([1], axis = 1)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199\n"
     ]
    }
   ],
   "source": [
    "# Apply the classifier\n",
    "# Divide the dataset into training and testing partition\n",
    "# predictions for testing partition\n",
    "# Print Number of mislabeled points\n",
    "X = df[df.columns[0:5]]\n",
    "Y = df[df.columns[5]]\n",
    "naive = GaussianNB()\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=1)\n",
    "naive.fit(X_train, Y_train)\n",
    "Y_pred = naive.predict(X_test)\n",
    "print((Y_pred != Y_test).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.84      0.80       343\n",
      "           1       0.48      0.09      0.15       133\n",
      "           2       0.00      0.00      0.00        23\n",
      "           3       0.17      1.00      0.29        20\n",
      "\n",
      "    accuracy                           0.62       519\n",
      "   macro avg       0.35      0.48      0.31       519\n",
      "weighted avg       0.64      0.62      0.58       519\n",
      "\n",
      "Confusion Matrix\n",
      "[[288  11   0  44]\n",
      " [ 71  12   0  50]\n",
      " [ 15   2   0   6]\n",
      " [  0   0   0  20]]\n",
      "\n",
      " Accuracy\n",
      "0.6165703275529865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/a/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Calculate and print confusion matrix and other performance measures\n",
    "print(classification_report(Y_test, Y_pred))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(Y_test, Y_pred))\n",
    "print(\"\\n Accuracy\")\n",
    "print(accuracy_score(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q6: Write your observation below in the performance of model in Q4 and Q6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the accuracy slightly dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
